# -*- coding: utf-8 -*-
"""Ai_asisstant_Edu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZzDvCVGoa396eehJ9vLYHtGihqT2L7x2
"""



# Import libraries
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import sounddevice as sd
import soundfile as sf
import os
import streamlit as st

# Load the language model and tokenizer
def load_models():
    # Load GPT-Neo model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-neo-125M")
    model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-neo-125M")
    return tokenizer, model

# Function to record audio
def record_audio(filename, duration=5, samplerate=16000):
    print("Recording audio...")
    audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')
    sd.wait()
    sf.write(filename, audio, samplerate)
    print("Recording complete.")

# Function to convert speech to text using Whisper
def audio_to_text(filename):
    import whisper
    model = whisper.load_model("base")
    result = model.transcribe(filename)
    return result["text"]

# Function to generate a response using the language model
def generate_response(tokenizer, model, text, conversation_history):
    # Add the user's input to the conversation history
    conversation_history += f"\nUser: {text}"

    # Generate a response using the model
    inputs = tokenizer(conversation_history, return_tensors="pt")
    outputs = model.generate(**inputs, max_length=500)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Add the model's response to the conversation history
    conversation_history += f"\nModel: {response}"

    return response, conversation_history

# Function to convert text to speech using Coqui TTS
def text_to_speech(text, output_file="output.wav"):
    from TTS.api import TTS
    tts = TTS(model_name="tts_models/fa/cv/vits", progress_bar=False, gpu=False)
    tts.tts_to_file(text=text, file_path=output_file)

# Streamlit user interface
def main():
    st.title("AI Assistant for Visually Impaired Students")

    # Load models
    tokenizer, model = load_models()

    # Manage conversation history
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = ""

    # Record audio
    audio_file = "input.wav"
    if st.button("Start Recording"):
        record_audio(audio_file)

    # Convert speech to text
    if os.path.exists(audio_file):
        user_input = audio_to_text(audio_file)
        st.write(f"User Input: {user_input}")

        # Generate response
        response, st.session_state.conversation_history = generate_response(
            tokenizer, model, user_input, st.session_state.conversation_history
        )
        st.write(f"Model Response: {response}")

        # Convert text to speech
        output_file = "output.wav"
        text_to_speech(response, output_file)

        # Play the audio response
        st.audio(output_file)

        # Display conversation history
        st.write("Conversation History:")
        st.write(st.session_state.conversation_history)

# Run the app
if __name__ == "__main__":
    main()


