# -*- coding: utf-8 -*-
"""Ai_asisstant_Edu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZzDvCVGoa396eehJ9vLYHtGihqT2L7x2
"""

# Import libraries
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import soundfile as sf
import os
import streamlit as st
from TTS.api import TTS

# Load the language model and tokenizer
def load_models():
    # Load GPT-Neo model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-neo-125M")
    model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-neo-125M")
    return tokenizer, model

# Function to convert speech to text using Whisper
def audio_to_text(filename):
    import whisper
    model = whisper.load_model("base")
    result = model.transcribe(filename)
    return result["text"]

# Function to generate a response using the language model
def generate_response(tokenizer, model, text, conversation_history):
    # Add the user's input to the conversation history
    conversation_history += f"\nUser: {text}"

    # Generate a response using the model
    inputs = tokenizer(conversation_history, return_tensors="pt")
    outputs = model.generate(**inputs, max_length=500)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Add the model's response to the conversation history
    conversation_history += f"\nModel: {response}"

    return response, conversation_history

# Function to convert text to speech using Coqui TTS
def text_to_speech(text, output_file="output.wav"):
    tts = TTS(model_name="tts_models/fa/cv/vits", progress_bar=False, gpu=False)
    tts.tts_to_file(text=text, file_path=output_file)

# Streamlit user interface
def main():
    st.title("AI Assistant for Visually Impaired Students")

    # Load models
    tokenizer, model = load_models()

    # Manage conversation history
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = ""

    # Upload audio file
    audio_file = st.file_uploader("Upload an audio file", type=["wav", "mp3"])

    if audio_file is not None:
        # Save the uploaded file
        with open("input.wav", "wb") as f:
            f.write(audio_file.getbuffer())

        # Convert speech to text
        user_input = audio_to_text("input.wav")
        st.write(f"User Input: {user_input}")

        # Generate response
        response, st.session_state.conversation_history = generate_response(
            tokenizer, model, user_input, st.session_state.conversation_history
        )
        st.write(f"Model Response: {response}")

        # Convert text to speech
        output_file = "output.wav"
        text_to_speech(response, output_file)

        # Play the audio response
        st.audio(output_file)

        # Display conversation history
        st.write("Conversation History:")
        st.write(st.session_state.conversation_history)

# Run the app
if __name__ == "__main__":
    main()
